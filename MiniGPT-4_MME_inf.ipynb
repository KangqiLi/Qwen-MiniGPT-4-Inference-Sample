{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7450d8-47a3-494e-8cea-7e55b4418680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from transformers import StoppingCriteriaList\n",
    "from transformers import LlamaForCausalLM\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.conversation import Chat, CONV_VISION_Vicuna0, CONV_VISION_LLama2, StoppingCriteriaSub\n",
    "\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "\n",
    "original_forward = LlamaForCausalLM.forward\n",
    "\n",
    "#def new forward\n",
    "def new_forward(self, *args, **kwargs):\n",
    "    #remove cache_position\n",
    "    kwargs.pop('cache_position', None)\n",
    "    return original_forward(self, *args, **kwargs)\n",
    "\n",
    "#\n",
    "LlamaForCausalLM.forward = new_forward\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"MME Dataset Processing\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--root-dir\", required=True, help=\"root directory of MME dataset\")\n",
    "    parser.add_argument(\"--output-file\", default=\"mme_results.csv\", help=\"output file name\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class MMEDataset:\n",
    "    def __init__(self, root_dir, split=\"test\"):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        file_pattern = os.path.join(self.root_dir, f\"{self.split}-*-of-00004-*.parquet\")\n",
    "        parquet_files = sorted(glob.glob(file_pattern))\n",
    "        \n",
    "        if not parquet_files:\n",
    "            raise FileNotFoundError(f\"No parquet files found matching pattern: {file_pattern}\")\n",
    "\n",
    "        for file_path in parquet_files:\n",
    "            print(f\"Loading data from {file_path}\")\n",
    "            if not os.path.exists(file_path):\n",
    "                raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "            df = pq.read_table(file_path).to_pandas()\n",
    "            data.append(df)\n",
    "        \n",
    "        data = pd.concat(data, ignore_index=True)\n",
    "        print(f\"Loaded {len(data)} examples.\")\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        print(f\"Image data type: {type(item['image'])}\")\n",
    "        print(f\"Image content: {item['image']}\")\n",
    "        return item['image'], item['question'], item['answer']\n",
    "\n",
    "\n",
    "# Model Initialization\n",
    "\n",
    "\n",
    "conv_dict = {'pretrain_vicuna0': CONV_VISION_Vicuna0,\n",
    "             'pretrain_llama2': CONV_VISION_LLama2}\n",
    "\n",
    "print('Initializing Chat')\n",
    "args = parse_args()\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "CONV_VISION = conv_dict[model_config.model_type]\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "\n",
    "stop_words_ids = [[835], [2277, 29937]]\n",
    "stop_words_ids = [torch.tensor(ids).to(device='cuda:{}'.format(args.gpu_id)) for ids in stop_words_ids]\n",
    "stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])\n",
    "\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id), stopping_criteria=stopping_criteria)\n",
    "print('Initialization Finished')\n",
    "\n",
    "\n",
    "# MME Dataset Processing\n",
    "\n",
    "\n",
    "def process_mme_dataset():\n",
    "    dataset = MMEDataset(args.root_dir)\n",
    "    results = []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        image_dict, question, ground_truth = dataset[idx]\n",
    "        \n",
    "        if isinstance(image_dict, dict) and 'bytes' in image_dict:\n",
    "            image = Image.open(BytesIO(image_dict['bytes']))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported image format: {type(image_dict)}\")\n",
    "        \n",
    "        chat_state = CONV_VISION.copy()\n",
    "        img_list = []\n",
    "        \n",
    "        chat.upload_img(image, chat_state, img_list)\n",
    "        chat.encode_img(img_list)\n",
    "        \n",
    "        chat.ask(question, chat_state)\n",
    "        \n",
    "        answer_kwargs = {\n",
    "            'conv': chat_state,\n",
    "            'img_list': img_list,\n",
    "            'num_beams': 1,\n",
    "            'temperature': 1.0,\n",
    "            'max_new_tokens': 300,\n",
    "            'max_length': 2000\n",
    "        }\n",
    "    \n",
    "        answer_kwargs.pop('cache_position', None)\n",
    "        model_answer = chat.answer(conv=chat_state,\n",
    "                                   img_list=img_list,\n",
    "                                   num_beams=1,\n",
    "                                   temperature=1.0,\n",
    "                                   max_new_tokens=300,\n",
    "                                   max_length=2000)[0]\n",
    "        \n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'ground_truth': ground_truth,\n",
    "            'model_answer': model_answer\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(args.output_file, index=False)\n",
    "    print(f\"Results saved to {args.output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_mme_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
